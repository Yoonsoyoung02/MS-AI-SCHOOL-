{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🕸️ 웹사이트 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium==4.17.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.17.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium==4.17.0) (2.3.0)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from selenium==4.17.0) (0.28.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from selenium==4.17.0) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from selenium==4.17.0) (2024.12.14)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from trio~=0.17->selenium==4.17.0) (25.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from trio~=0.17->selenium==4.17.0) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from trio~=0.17->selenium==4.17.0) (3.10)\n",
      "Requirement already satisfied: outcome in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from trio~=0.17->selenium==4.17.0) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from trio~=0.17->selenium==4.17.0) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from trio~=0.17->selenium==4.17.0) (1.17.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from trio-websocket~=0.9->selenium==4.17.0) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium==4.17.0) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium==4.17.0) (2.22)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium==4.17.0) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "# 웹 사이트 크롤링\n",
    "!pip install selenium==4.17.0, typing-extensions openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: selenium\n",
      "Version: 4.17.0\n",
      "Summary: \n",
      "Home-page: https://www.selenium.dev\n",
      "Author: \n",
      "Author-email: \n",
      "License: Apache 2.0\n",
      "Location: c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\n",
      "Requires: certifi, trio, trio-websocket, urllib3\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.13.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (2024.12.14)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from beautifulsoup4) (2.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from beautifulsoup4) (4.12.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.32.3)\n",
      "Collecting webdriver_manager\n",
      "  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (2024.12.14)\n",
      "Collecting python-dotenv (from webdriver_manager)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from webdriver_manager) (24.2)\n",
      "Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv, webdriver_manager\n",
      "Successfully installed python-dotenv-1.0.1 webdriver_manager-4.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install requests webdriver_manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🖱️웹드라이브 설정 및 웹페이지 접근\n",
    "###### Selenium을 사용하여 웹페이지에 접근하고, BeautifulSoup을 통해 HTML을 파싱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver # Selenium 웹드라이버\n",
    "from selenium.webdriver.chrome.service import Service # 웹드라이버 서비스 관리\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup HTML 파싱을 위한 BeautifulSoup\n",
    "import time # 페이지 로딩 대기 시간 설정\n",
    "\n",
    "# 웹드라이버 설정\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--headless')  # 브라우저 창을 띄우지 않음\n",
    "options.add_argument('--disable-dev-shm-usage') # 메모리 사용 최적화\n",
    "\n",
    "# 웹드라이버 실행\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# 대상 웹페이지 URL\n",
    "url = 'https://www.allrecipes.com/'\n",
    "\n",
    "# 웹페이지 열기\n",
    "driver.get(url)\n",
    "\n",
    "# 페이지 로딩 대기\n",
    "time.sleep(3)  # 필요에 따라 조정\n",
    "\n",
    "# 페이지 소스 가져오기\n",
    "page_source = driver.page_source\n",
    "\n",
    "# BeautifulSoup으로 HTML 파싱\n",
    "soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "# 웹드라이버 종료\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded downloaded_images\\image_1.jpg\n",
      "Successfully downloaded downloaded_images\\image_2.jpg\n",
      "Successfully downloaded downloaded_images\\image_3.jpg\n",
      "Successfully downloaded downloaded_images\\image_4.jpg\n",
      "Successfully downloaded downloaded_images\\image_5.jpg\n",
      "Successfully downloaded downloaded_images\\image_6.jpg\n",
      "Successfully downloaded downloaded_images\\image_7.jpg\n",
      "Successfully downloaded downloaded_images\\image_8.jpg\n",
      "Successfully downloaded downloaded_images\\image_9.jpg\n",
      "Successfully downloaded downloaded_images\\image_10.jpg\n",
      "Successfully downloaded downloaded_images\\image_12.jpg\n",
      "Successfully downloaded downloaded_images\\image_14.jpg\n",
      "Successfully downloaded downloaded_images\\image_16.jpg\n",
      "Successfully downloaded downloaded_images\\image_18.jpg\n",
      "Successfully downloaded downloaded_images\\image_20.jpg\n",
      "Successfully downloaded downloaded_images\\image_22.jpg\n",
      "Successfully downloaded downloaded_images\\image_24.jpg\n",
      "Successfully downloaded downloaded_images\\image_26.jpg\n",
      "Successfully downloaded downloaded_images\\image_28.jpg\n",
      "Successfully downloaded downloaded_images\\image_30.jpg\n",
      "Successfully downloaded downloaded_images\\image_32.jpg\n",
      "Successfully downloaded downloaded_images\\image_34.jpg\n",
      "Successfully downloaded downloaded_images\\image_36.jpg\n",
      "Successfully downloaded downloaded_images\\image_38.jpg\n",
      "Successfully downloaded downloaded_images\\image_40.jpg\n",
      "Successfully downloaded downloaded_images\\image_42.jpg\n",
      "Successfully downloaded downloaded_images\\image_44.jpg\n",
      "Successfully downloaded downloaded_images\\image_46.jpg\n",
      "Successfully downloaded downloaded_images\\image_48.jpg\n",
      "Successfully downloaded downloaded_images\\image_50.jpg\n",
      "Successfully downloaded downloaded_images\\image_52.jpg\n",
      "Successfully downloaded downloaded_images\\image_54.jpg\n",
      "Successfully downloaded downloaded_images\\image_56.jpg\n",
      "Successfully downloaded downloaded_images\\image_58.jpg\n",
      "Successfully downloaded downloaded_images\\image_60.jpg\n",
      "Successfully downloaded downloaded_images\\image_62.jpg\n",
      "Successfully downloaded downloaded_images\\image_64.jpg\n",
      "Successfully downloaded downloaded_images\\image_66.jpg\n",
      "Successfully downloaded downloaded_images\\image_68.jpg\n",
      "Successfully downloaded downloaded_images\\image_70.jpg\n",
      "Successfully downloaded downloaded_images\\image_72.jpg\n",
      "Successfully downloaded downloaded_images\\image_74.jpg\n",
      "Successfully downloaded downloaded_images\\image_76.jpg\n",
      "Successfully downloaded downloaded_images\\image_78.jpg\n",
      "Successfully downloaded downloaded_images\\image_80.jpg\n",
      "Successfully downloaded downloaded_images\\image_82.jpg\n",
      "Successfully downloaded downloaded_images\\image_84.jpg\n",
      "Successfully downloaded downloaded_images\\image_86.jpg\n",
      "Successfully downloaded downloaded_images\\image_88.jpg\n",
      "Successfully downloaded downloaded_images\\image_90.jpg\n",
      "Successfully downloaded downloaded_images\\image_92.jpg\n",
      "Successfully downloaded downloaded_images\\image_94.jpg\n",
      "Successfully downloaded downloaded_images\\image_96.jpg\n",
      "Successfully downloaded downloaded_images\\image_98.jpg\n",
      "Successfully downloaded downloaded_images\\image_100.jpg\n",
      "Successfully downloaded downloaded_images\\image_102.jpg\n",
      "Successfully downloaded downloaded_images\\image_104.jpg\n",
      "Successfully downloaded downloaded_images\\image_106.jpg\n",
      "Successfully downloaded downloaded_images\\image_108.jpg\n",
      "Successfully downloaded downloaded_images\\image_110.jpg\n",
      "Successfully downloaded downloaded_images\\image_112.jpg\n",
      "Successfully downloaded downloaded_images\\image_114.jpg\n",
      "Successfully downloaded downloaded_images\\image_116.jpg\n",
      "Successfully downloaded downloaded_images\\image_117.jpg\n"
     ]
    }
   ],
   "source": [
    "# 웹에서 데이터를 가져오기 위한 라이브러리\n",
    "import requests\n",
    " # 파일 및 디렉토리 관련 작업을 위한 라이브러리\n",
    "import os\n",
    "\n",
    "# 저장할 디렉토리 설정\n",
    "save_dir = 'downloaded_images'\n",
    "\n",
    "# 폴더가 없으면 생성\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# 이미지 태그 찾기\n",
    "# soup.find_all('img'): HTML에서 <img> 태그를 모두 찾아 리스트로 반환\n",
    "images = soup.find_all('img')\n",
    "\n",
    "# 이미지 다운로드\n",
    "for idx, img in enumerate(images):\n",
    "    img_url = img.get('src')\n",
    "    if img_url:\n",
    "        try:\n",
    "            # 이미지 데이터 가져오기(img_url에서 HTTP GET 요청을 보내서 이미지 데이터를 가져옴)\n",
    "            img_data = requests.get(img_url).content\n",
    "            # 파일 경로 설정\n",
    "            img_filename = os.path.join(save_dir, f'image_{idx + 1}.jpg')\n",
    "            # 이미지 저장\n",
    "            with open(img_filename, 'wb') as f:\n",
    "                f.write(img_data)\n",
    "            print(f'Successfully downloaded {img_filename}')\n",
    "        except Exception as e:\n",
    "            print(f'Failed to download image at {img_url}: {e}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 브라우저 제어\n",
    "##### - get(URL): 페이지로 이동하기\n",
    "##### - back(): 뒤로 이동하기\n",
    "##### - forward(): 앞으로 가기\n",
    "##### - refresh : 새로고침\n",
    "##### - maximize_window(): 브라우저 크기 최대화\n",
    "##### - minimize_window() : 브라우저크기 최소화\n",
    "##### - close() : 웹드라이버로 생성한 현재 창 종료\n",
    "##### - quit() : 웹드라이버로 생성한 모든 창 종료"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
